{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ハンズオン: TensorBoardを使ったモデルのチューニング\n",
    "    - 質問などありましたら， 上野山 ( t.uenoyama@gmail.com, @araneko ) までお気軽に"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 必要なモジュールを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNISTデータの取得とプレビュー\n",
    "- mnist.train.images: 訓練用イメージデータが配列で格納されている。1枚のイメージはベクトルになっていることに注意。\n",
    "- mnist.train.labels: 訓練用のラベルデータ。1-of-K 表現。\n",
    "- mnist.validation.images: バリデーション用イメージデータ。\n",
    "- mnist.validation.labels: バリデーション用ラベルデータ。\n",
    "- mnist.test.images: テスト用イメージデータ。\n",
    "- mnist.test.labels: テスト用ラベルデータ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# データのダウンロードと展開\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  55000\n",
      "valid:  5000\n",
      "test:  10000\n"
     ]
    }
   ],
   "source": [
    "# データセットの枚数を確認\n",
    "print('train: ', len(mnist.train.images))\n",
    "print('valid: ', len(mnist.validation.images))\n",
    "print('test: ', len(mnist.test.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3 4 6]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAABoCAYAAAA6u6ElAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ8YAQTbaMmTIkDFA+P8EhkMgQhVhXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d249b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 訓練画像の先頭４毎を描画\n",
    "for i in range(0, 4):\n",
    "    plt.subplot(141 + i)\n",
    "    plt.imshow(-mnist.train.images[i].reshape(28, 28), cmap=plt.cm.gray)\n",
    "print(np.argmax(mnist.train.labels[0:4,], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow でMLP\n",
    "\n",
    "別のシェルで TensorBoard を立ち上げておく。\n",
    "```\n",
    "mkdir -p data\n",
    "rm -rf data/*\n",
    "tensorboard --logdir=$PWD/data\n",
    "```\n",
    "その後，ブラウザで `http://127.0.0.1:6006/` を開く。\n",
    "\n",
    "### 学習したいモデルを記述する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 入力変数と出力変数のプレースホルダを生成\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='Image')\n",
    "y_ = tf.placeholder(tf.float32, [None, 10], name='true_label')\n",
    "\n",
    "# モデル式 (入力層:784ノード, 隠れ層:1000ノード, 隠れ層:1000ノード, 出力層:10ノード)\n",
    "H1_NODE = 1000  # ★ 変えてみよう\n",
    "H2_NODE = 1000  # ★ 変えてみよう\n",
    "\n",
    "with tf.name_scope('fc_1'):\n",
    "    W1 = tf.Variable(tf.truncated_normal([784, H1_NODE]), name='weight') \n",
    "    b1 = tf.Variable(tf.zeros([H1_NODE]), name='bias')\n",
    "    h1 = tf.sigmoid(tf.matmul(x, W1) + b1) # 入力層->隠れ層\n",
    "\n",
    "with tf.name_scope('fc_2'):\n",
    "    W2 = tf.Variable(tf.truncated_normal([H1_NODE, H2_NODE]), name='weight')\n",
    "    b2 = tf.Variable(tf.zeros([H2_NODE]), name='bias')\n",
    "    h2 = tf.sigmoid(tf.matmul(h1, W2) + b2) # 隠れ層->隠れ層\n",
    "\n",
    "with tf.name_scope('fc_3'):\n",
    "    W3 = tf.Variable(tf.truncated_normal([H2_NODE, 10]), name='weight')\n",
    "    b3 = tf.Variable(tf.zeros([10]), name='bias')\n",
    "    u = tf.matmul(h2, W3) + b3    # 隠れ層->出力層 (ロジット)\n",
    "    y = tf.nn.softmax(u)         # 隠れ層->出力層 (ソフトマックス後)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習やテストに必要な関数を定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    # 誤差関数(loss)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(u, y_), name='Xent')\n",
    "    xent_summ = tf.scalar_summary('learning/XEnt', loss)\n",
    "    # 最適化手段(最急降下法)\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss, global_step=global_step)\n",
    "\n",
    "with tf.name_scope('eval'):\n",
    "    # 正答率\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='Accuracy')\n",
    "    acc_summ = tf.scalar_summary('learning/Accuracy', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実際に学習処理を実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# すべてのサマリーを統合\n",
    "merged_summ = tf.merge_all_summaries()\n",
    "\n",
    "# セッションを準備\n",
    "sess = tf.Session()\n",
    "\n",
    "# セッション作成後に SummaryWriter を呼ぶことで， グラフ構造が出力される。\n",
    "SESSION_NAME = 'sgd0.1_N1000_1000x1000'  # ★★ 毎回名前を変えると良い\n",
    "train_writer = tf.train.SummaryWriter('data/mnist_' + SESSION_NAME + '/train', graph=sess.graph, flush_secs=10)\n",
    "valid_writer = tf.train.SummaryWriter('data/mnist_' + SESSION_NAME + '/valid', flush_secs=10)\n",
    "\n",
    "# 変数を初期化\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=  1, Xent(train)=4.89, Acc(train)=0.10, Xent(valid)=4.66, Acc(valid)=0.10\n",
      "step= 11, Xent(train)=3.69, Acc(train)=0.09, Xent(valid)=3.28, Acc(valid)=0.10\n",
      "step= 21, Xent(train)=2.88, Acc(train)=0.11, Xent(valid)=2.82, Acc(valid)=0.12\n",
      "step= 31, Xent(train)=2.56, Acc(train)=0.14, Xent(valid)=2.60, Acc(valid)=0.14\n",
      "step= 41, Xent(train)=2.31, Acc(train)=0.25, Xent(valid)=2.47, Acc(valid)=0.17\n",
      "step= 51, Xent(train)=2.41, Acc(train)=0.19, Xent(valid)=2.34, Acc(valid)=0.20\n",
      "step= 61, Xent(train)=2.02, Acc(train)=0.35, Xent(valid)=2.25, Acc(valid)=0.23\n",
      "step= 71, Xent(train)=1.90, Acc(train)=0.33, Xent(valid)=2.15, Acc(valid)=0.26\n",
      "step= 81, Xent(train)=1.88, Acc(train)=0.32, Xent(valid)=2.07, Acc(valid)=0.30\n",
      "step= 91, Xent(train)=1.72, Acc(train)=0.37, Xent(valid)=2.01, Acc(valid)=0.31\n",
      "step=101, Xent(train)=1.90, Acc(train)=0.41, Xent(valid)=1.95, Acc(valid)=0.34\n",
      "step=111, Xent(train)=1.96, Acc(train)=0.33, Xent(valid)=1.90, Acc(valid)=0.35\n",
      "step=121, Xent(train)=1.93, Acc(train)=0.36, Xent(valid)=1.85, Acc(valid)=0.39\n",
      "step=131, Xent(train)=1.71, Acc(train)=0.43, Xent(valid)=1.80, Acc(valid)=0.40\n",
      "step=141, Xent(train)=1.71, Acc(train)=0.48, Xent(valid)=1.76, Acc(valid)=0.41\n",
      "step=151, Xent(train)=1.66, Acc(train)=0.47, Xent(valid)=1.72, Acc(valid)=0.43\n",
      "step=161, Xent(train)=1.45, Acc(train)=0.54, Xent(valid)=1.69, Acc(valid)=0.44\n",
      "step=171, Xent(train)=1.51, Acc(train)=0.55, Xent(valid)=1.65, Acc(valid)=0.45\n",
      "step=181, Xent(train)=1.58, Acc(train)=0.46, Xent(valid)=1.61, Acc(valid)=0.47\n",
      "step=191, Xent(train)=1.39, Acc(train)=0.61, Xent(valid)=1.58, Acc(valid)=0.49\n",
      "step=201, Xent(train)=1.51, Acc(train)=0.47, Xent(valid)=1.55, Acc(valid)=0.50\n",
      "step=211, Xent(train)=1.46, Acc(train)=0.52, Xent(valid)=1.52, Acc(valid)=0.51\n",
      "step=221, Xent(train)=1.37, Acc(train)=0.56, Xent(valid)=1.50, Acc(valid)=0.51\n",
      "step=231, Xent(train)=1.41, Acc(train)=0.56, Xent(valid)=1.47, Acc(valid)=0.54\n",
      "step=241, Xent(train)=1.42, Acc(train)=0.56, Xent(valid)=1.45, Acc(valid)=0.55\n",
      "step=251, Xent(train)=1.37, Acc(train)=0.57, Xent(valid)=1.43, Acc(valid)=0.55\n",
      "step=261, Xent(train)=1.37, Acc(train)=0.54, Xent(valid)=1.40, Acc(valid)=0.56\n",
      "step=271, Xent(train)=1.22, Acc(train)=0.58, Xent(valid)=1.38, Acc(valid)=0.56\n",
      "step=281, Xent(train)=1.21, Acc(train)=0.67, Xent(valid)=1.36, Acc(valid)=0.57\n",
      "step=291, Xent(train)=1.23, Acc(train)=0.62, Xent(valid)=1.34, Acc(valid)=0.58\n",
      "step=301, Xent(train)=1.17, Acc(train)=0.64, Xent(valid)=1.32, Acc(valid)=0.60\n",
      "step=311, Xent(train)=1.22, Acc(train)=0.59, Xent(valid)=1.30, Acc(valid)=0.61\n",
      "step=321, Xent(train)=1.32, Acc(train)=0.51, Xent(valid)=1.28, Acc(valid)=0.61\n",
      "step=331, Xent(train)=1.13, Acc(train)=0.66, Xent(valid)=1.27, Acc(valid)=0.60\n",
      "step=341, Xent(train)=1.13, Acc(train)=0.62, Xent(valid)=1.25, Acc(valid)=0.62\n",
      "step=351, Xent(train)=1.14, Acc(train)=0.67, Xent(valid)=1.23, Acc(valid)=0.63\n",
      "step=361, Xent(train)=0.95, Acc(train)=0.73, Xent(valid)=1.22, Acc(valid)=0.63\n",
      "step=371, Xent(train)=1.09, Acc(train)=0.71, Xent(valid)=1.21, Acc(valid)=0.62\n",
      "step=381, Xent(train)=1.21, Acc(train)=0.60, Xent(valid)=1.19, Acc(valid)=0.64\n",
      "step=391, Xent(train)=1.09, Acc(train)=0.68, Xent(valid)=1.19, Acc(valid)=0.64\n",
      "step=401, Xent(train)=1.12, Acc(train)=0.64, Xent(valid)=1.17, Acc(valid)=0.65\n",
      "step=411, Xent(train)=1.07, Acc(train)=0.68, Xent(valid)=1.16, Acc(valid)=0.65\n",
      "step=421, Xent(train)=1.07, Acc(train)=0.70, Xent(valid)=1.15, Acc(valid)=0.65\n",
      "step=431, Xent(train)=1.03, Acc(train)=0.69, Xent(valid)=1.13, Acc(valid)=0.66\n",
      "step=441, Xent(train)=1.14, Acc(train)=0.65, Xent(valid)=1.12, Acc(valid)=0.67\n",
      "step=451, Xent(train)=0.94, Acc(train)=0.73, Xent(valid)=1.12, Acc(valid)=0.67\n",
      "step=461, Xent(train)=0.91, Acc(train)=0.69, Xent(valid)=1.11, Acc(valid)=0.67\n",
      "step=471, Xent(train)=1.00, Acc(train)=0.69, Xent(valid)=1.09, Acc(valid)=0.68\n",
      "step=481, Xent(train)=1.00, Acc(train)=0.68, Xent(valid)=1.08, Acc(valid)=0.68\n",
      "step=491, Xent(train)=1.10, Acc(train)=0.64, Xent(valid)=1.07, Acc(valid)=0.69\n",
      "step=501, Xent(train)=0.92, Acc(train)=0.76, Xent(valid)=1.07, Acc(valid)=0.69\n",
      "step=511, Xent(train)=0.77, Acc(train)=0.74, Xent(valid)=1.05, Acc(valid)=0.69\n",
      "step=521, Xent(train)=0.98, Acc(train)=0.77, Xent(valid)=1.05, Acc(valid)=0.69\n",
      "step=531, Xent(train)=1.08, Acc(train)=0.66, Xent(valid)=1.04, Acc(valid)=0.69\n",
      "step=541, Xent(train)=1.03, Acc(train)=0.69, Xent(valid)=1.04, Acc(valid)=0.69\n",
      "step=551, Xent(train)=0.94, Acc(train)=0.74, Xent(valid)=1.02, Acc(valid)=0.69\n",
      "step=561, Xent(train)=0.95, Acc(train)=0.69, Xent(valid)=1.01, Acc(valid)=0.70\n",
      "step=571, Xent(train)=1.00, Acc(train)=0.70, Xent(valid)=1.01, Acc(valid)=0.70\n",
      "step=581, Xent(train)=1.00, Acc(train)=0.73, Xent(valid)=1.00, Acc(valid)=0.70\n",
      "step=591, Xent(train)=0.87, Acc(train)=0.73, Xent(valid)=0.99, Acc(valid)=0.71\n",
      "step=601, Xent(train)=1.00, Acc(train)=0.70, Xent(valid)=0.98, Acc(valid)=0.71\n",
      "step=611, Xent(train)=0.75, Acc(train)=0.77, Xent(valid)=0.98, Acc(valid)=0.71\n",
      "step=621, Xent(train)=0.89, Acc(train)=0.75, Xent(valid)=0.97, Acc(valid)=0.71\n",
      "step=631, Xent(train)=0.69, Acc(train)=0.78, Xent(valid)=0.97, Acc(valid)=0.70\n",
      "step=641, Xent(train)=1.14, Acc(train)=0.62, Xent(valid)=0.96, Acc(valid)=0.71\n",
      "step=651, Xent(train)=0.87, Acc(train)=0.75, Xent(valid)=0.96, Acc(valid)=0.71\n",
      "step=661, Xent(train)=0.80, Acc(train)=0.77, Xent(valid)=0.95, Acc(valid)=0.71\n",
      "step=671, Xent(train)=0.97, Acc(train)=0.71, Xent(valid)=0.94, Acc(valid)=0.71\n",
      "step=681, Xent(train)=0.80, Acc(train)=0.74, Xent(valid)=0.94, Acc(valid)=0.71\n",
      "step=691, Xent(train)=0.75, Acc(train)=0.80, Xent(valid)=0.94, Acc(valid)=0.71\n",
      "step=701, Xent(train)=0.86, Acc(train)=0.69, Xent(valid)=0.93, Acc(valid)=0.72\n",
      "step=711, Xent(train)=0.59, Acc(train)=0.81, Xent(valid)=0.93, Acc(valid)=0.71\n",
      "step=721, Xent(train)=0.74, Acc(train)=0.74, Xent(valid)=0.92, Acc(valid)=0.71\n",
      "step=731, Xent(train)=0.72, Acc(train)=0.79, Xent(valid)=0.92, Acc(valid)=0.72\n",
      "step=741, Xent(train)=0.75, Acc(train)=0.79, Xent(valid)=0.91, Acc(valid)=0.73\n",
      "step=751, Xent(train)=0.77, Acc(train)=0.76, Xent(valid)=0.91, Acc(valid)=0.72\n",
      "step=761, Xent(train)=0.71, Acc(train)=0.75, Xent(valid)=0.90, Acc(valid)=0.72\n",
      "step=771, Xent(train)=0.80, Acc(train)=0.79, Xent(valid)=0.90, Acc(valid)=0.73\n",
      "step=781, Xent(train)=0.81, Acc(train)=0.76, Xent(valid)=0.90, Acc(valid)=0.72\n",
      "step=791, Xent(train)=0.66, Acc(train)=0.77, Xent(valid)=0.89, Acc(valid)=0.73\n",
      "step=801, Xent(train)=0.94, Acc(train)=0.72, Xent(valid)=0.88, Acc(valid)=0.73\n",
      "step=811, Xent(train)=0.73, Acc(train)=0.74, Xent(valid)=0.88, Acc(valid)=0.73\n",
      "step=821, Xent(train)=0.69, Acc(train)=0.80, Xent(valid)=0.88, Acc(valid)=0.73\n",
      "step=831, Xent(train)=0.55, Acc(train)=0.87, Xent(valid)=0.88, Acc(valid)=0.73\n",
      "step=841, Xent(train)=0.70, Acc(train)=0.82, Xent(valid)=0.87, Acc(valid)=0.74\n",
      "step=851, Xent(train)=0.72, Acc(train)=0.76, Xent(valid)=0.87, Acc(valid)=0.73\n",
      "step=861, Xent(train)=0.85, Acc(train)=0.70, Xent(valid)=0.87, Acc(valid)=0.74\n",
      "step=871, Xent(train)=0.72, Acc(train)=0.79, Xent(valid)=0.86, Acc(valid)=0.73\n",
      "step=881, Xent(train)=0.65, Acc(train)=0.76, Xent(valid)=0.86, Acc(valid)=0.73\n",
      "step=891, Xent(train)=0.61, Acc(train)=0.79, Xent(valid)=0.86, Acc(valid)=0.73\n",
      "step=901, Xent(train)=0.81, Acc(train)=0.76, Xent(valid)=0.85, Acc(valid)=0.73\n",
      "step=911, Xent(train)=0.61, Acc(train)=0.81, Xent(valid)=0.85, Acc(valid)=0.74\n",
      "step=921, Xent(train)=0.59, Acc(train)=0.81, Xent(valid)=0.85, Acc(valid)=0.74\n",
      "step=931, Xent(train)=0.69, Acc(train)=0.77, Xent(valid)=0.85, Acc(valid)=0.74\n",
      "step=941, Xent(train)=0.81, Acc(train)=0.67, Xent(valid)=0.83, Acc(valid)=0.74\n",
      "step=951, Xent(train)=0.65, Acc(train)=0.81, Xent(valid)=0.83, Acc(valid)=0.74\n",
      "step=961, Xent(train)=0.65, Acc(train)=0.77, Xent(valid)=0.83, Acc(valid)=0.75\n",
      "step=971, Xent(train)=0.76, Acc(train)=0.77, Xent(valid)=0.83, Acc(valid)=0.74\n",
      "step=981, Xent(train)=0.71, Acc(train)=0.77, Xent(valid)=0.83, Acc(valid)=0.74\n",
      "step=991, Xent(train)=0.65, Acc(train)=0.78, Xent(valid)=0.82, Acc(valid)=0.75\n",
      "step=1001, Xent(train)=0.70, Acc(train)=0.80, Xent(valid)=0.82, Acc(valid)=0.75\n",
      "step=1011, Xent(train)=0.67, Acc(train)=0.82, Xent(valid)=0.81, Acc(valid)=0.74\n",
      "step=1021, Xent(train)=0.78, Acc(train)=0.78, Xent(valid)=0.81, Acc(valid)=0.75\n",
      "step=1031, Xent(train)=0.88, Acc(train)=0.75, Xent(valid)=0.81, Acc(valid)=0.74\n",
      "step=1041, Xent(train)=0.76, Acc(train)=0.76, Xent(valid)=0.80, Acc(valid)=0.75\n",
      "step=1051, Xent(train)=0.61, Acc(train)=0.80, Xent(valid)=0.80, Acc(valid)=0.75\n",
      "step=1061, Xent(train)=0.71, Acc(train)=0.78, Xent(valid)=0.80, Acc(valid)=0.75\n",
      "step=1071, Xent(train)=0.71, Acc(train)=0.75, Xent(valid)=0.80, Acc(valid)=0.75\n",
      "step=1081, Xent(train)=0.57, Acc(train)=0.82, Xent(valid)=0.80, Acc(valid)=0.75\n",
      "step=1091, Xent(train)=0.64, Acc(train)=0.79, Xent(valid)=0.79, Acc(valid)=0.75\n",
      "step=1101, Xent(train)=0.67, Acc(train)=0.82, Xent(valid)=0.79, Acc(valid)=0.75\n",
      "step=1111, Xent(train)=0.53, Acc(train)=0.87, Xent(valid)=0.79, Acc(valid)=0.76\n",
      "step=1121, Xent(train)=0.59, Acc(train)=0.82, Xent(valid)=0.78, Acc(valid)=0.75\n",
      "step=1131, Xent(train)=0.71, Acc(train)=0.81, Xent(valid)=0.78, Acc(valid)=0.75\n",
      "step=1141, Xent(train)=0.66, Acc(train)=0.81, Xent(valid)=0.78, Acc(valid)=0.75\n",
      "step=1151, Xent(train)=0.68, Acc(train)=0.76, Xent(valid)=0.78, Acc(valid)=0.76\n",
      "step=1161, Xent(train)=0.62, Acc(train)=0.80, Xent(valid)=0.78, Acc(valid)=0.76\n",
      "step=1171, Xent(train)=0.64, Acc(train)=0.80, Xent(valid)=0.78, Acc(valid)=0.75\n",
      "step=1181, Xent(train)=0.58, Acc(train)=0.83, Xent(valid)=0.78, Acc(valid)=0.76\n",
      "step=1191, Xent(train)=0.62, Acc(train)=0.84, Xent(valid)=0.77, Acc(valid)=0.76\n",
      "step=1201, Xent(train)=0.70, Acc(train)=0.82, Xent(valid)=0.76, Acc(valid)=0.76\n",
      "step=1211, Xent(train)=0.67, Acc(train)=0.78, Xent(valid)=0.76, Acc(valid)=0.76\n",
      "step=1221, Xent(train)=0.54, Acc(train)=0.83, Xent(valid)=0.76, Acc(valid)=0.76\n",
      "step=1231, Xent(train)=0.53, Acc(train)=0.85, Xent(valid)=0.76, Acc(valid)=0.76\n",
      "step=1241, Xent(train)=0.76, Acc(train)=0.80, Xent(valid)=0.76, Acc(valid)=0.77\n",
      "step=1251, Xent(train)=0.68, Acc(train)=0.80, Xent(valid)=0.75, Acc(valid)=0.77\n",
      "step=1261, Xent(train)=0.74, Acc(train)=0.75, Xent(valid)=0.75, Acc(valid)=0.76\n",
      "step=1271, Xent(train)=0.43, Acc(train)=0.87, Xent(valid)=0.75, Acc(valid)=0.76\n",
      "step=1281, Xent(train)=0.58, Acc(train)=0.88, Xent(valid)=0.75, Acc(valid)=0.76\n",
      "step=1291, Xent(train)=0.55, Acc(train)=0.84, Xent(valid)=0.74, Acc(valid)=0.76\n",
      "step=1301, Xent(train)=0.61, Acc(train)=0.80, Xent(valid)=0.74, Acc(valid)=0.76\n",
      "step=1311, Xent(train)=0.54, Acc(train)=0.89, Xent(valid)=0.74, Acc(valid)=0.77\n",
      "step=1321, Xent(train)=0.64, Acc(train)=0.78, Xent(valid)=0.74, Acc(valid)=0.77\n",
      "step=1331, Xent(train)=0.71, Acc(train)=0.80, Xent(valid)=0.74, Acc(valid)=0.77\n",
      "step=1341, Xent(train)=0.40, Acc(train)=0.86, Xent(valid)=0.74, Acc(valid)=0.76\n",
      "step=1351, Xent(train)=0.53, Acc(train)=0.82, Xent(valid)=0.74, Acc(valid)=0.77\n",
      "step=1361, Xent(train)=0.54, Acc(train)=0.83, Xent(valid)=0.73, Acc(valid)=0.77\n",
      "step=1371, Xent(train)=0.38, Acc(train)=0.87, Xent(valid)=0.73, Acc(valid)=0.77\n",
      "step=1381, Xent(train)=0.64, Acc(train)=0.80, Xent(valid)=0.73, Acc(valid)=0.77\n",
      "step=1391, Xent(train)=0.66, Acc(train)=0.84, Xent(valid)=0.73, Acc(valid)=0.77\n",
      "step=1401, Xent(train)=0.50, Acc(train)=0.84, Xent(valid)=0.72, Acc(valid)=0.77\n",
      "step=1411, Xent(train)=0.55, Acc(train)=0.86, Xent(valid)=0.72, Acc(valid)=0.78\n",
      "step=1421, Xent(train)=0.47, Acc(train)=0.87, Xent(valid)=0.73, Acc(valid)=0.77\n",
      "step=1431, Xent(train)=0.52, Acc(train)=0.82, Xent(valid)=0.72, Acc(valid)=0.78\n",
      "step=1441, Xent(train)=0.56, Acc(train)=0.83, Xent(valid)=0.72, Acc(valid)=0.78\n",
      "step=1451, Xent(train)=0.60, Acc(train)=0.85, Xent(valid)=0.71, Acc(valid)=0.79\n",
      "step=1461, Xent(train)=0.67, Acc(train)=0.81, Xent(valid)=0.71, Acc(valid)=0.78\n",
      "step=1471, Xent(train)=0.67, Acc(train)=0.78, Xent(valid)=0.71, Acc(valid)=0.78\n",
      "step=1481, Xent(train)=0.46, Acc(train)=0.91, Xent(valid)=0.71, Acc(valid)=0.77\n",
      "step=1491, Xent(train)=0.46, Acc(train)=0.86, Xent(valid)=0.71, Acc(valid)=0.77\n",
      "step=1501, Xent(train)=0.34, Acc(train)=0.92, Xent(valid)=0.71, Acc(valid)=0.77\n",
      "step=1511, Xent(train)=0.58, Acc(train)=0.83, Xent(valid)=0.70, Acc(valid)=0.78\n",
      "step=1521, Xent(train)=0.78, Acc(train)=0.77, Xent(valid)=0.70, Acc(valid)=0.78\n",
      "step=1531, Xent(train)=0.63, Acc(train)=0.80, Xent(valid)=0.70, Acc(valid)=0.79\n",
      "step=1541, Xent(train)=0.45, Acc(train)=0.85, Xent(valid)=0.70, Acc(valid)=0.79\n",
      "step=1551, Xent(train)=0.56, Acc(train)=0.80, Xent(valid)=0.70, Acc(valid)=0.78\n",
      "step=1561, Xent(train)=0.65, Acc(train)=0.80, Xent(valid)=0.70, Acc(valid)=0.79\n",
      "step=1571, Xent(train)=0.30, Acc(train)=0.92, Xent(valid)=0.70, Acc(valid)=0.79\n",
      "step=1581, Xent(train)=0.46, Acc(train)=0.86, Xent(valid)=0.69, Acc(valid)=0.79\n",
      "step=1591, Xent(train)=0.61, Acc(train)=0.81, Xent(valid)=0.69, Acc(valid)=0.79\n",
      "step=1601, Xent(train)=0.45, Acc(train)=0.84, Xent(valid)=0.69, Acc(valid)=0.79\n",
      "step=1611, Xent(train)=0.46, Acc(train)=0.86, Xent(valid)=0.69, Acc(valid)=0.78\n",
      "step=1621, Xent(train)=0.51, Acc(train)=0.81, Xent(valid)=0.68, Acc(valid)=0.79\n",
      "step=1631, Xent(train)=0.49, Acc(train)=0.83, Xent(valid)=0.69, Acc(valid)=0.79\n",
      "step=1641, Xent(train)=0.45, Acc(train)=0.86, Xent(valid)=0.68, Acc(valid)=0.80\n",
      "step=1651, Xent(train)=0.70, Acc(train)=0.78, Xent(valid)=0.68, Acc(valid)=0.79\n",
      "step=1661, Xent(train)=0.55, Acc(train)=0.84, Xent(valid)=0.68, Acc(valid)=0.80\n",
      "step=1671, Xent(train)=0.56, Acc(train)=0.85, Xent(valid)=0.67, Acc(valid)=0.80\n",
      "step=1681, Xent(train)=0.51, Acc(train)=0.82, Xent(valid)=0.68, Acc(valid)=0.79\n",
      "step=1691, Xent(train)=0.58, Acc(train)=0.83, Xent(valid)=0.67, Acc(valid)=0.80\n",
      "step=1701, Xent(train)=0.56, Acc(train)=0.83, Xent(valid)=0.67, Acc(valid)=0.79\n",
      "step=1711, Xent(train)=0.50, Acc(train)=0.86, Xent(valid)=0.67, Acc(valid)=0.80\n",
      "step=1721, Xent(train)=0.50, Acc(train)=0.85, Xent(valid)=0.67, Acc(valid)=0.79\n",
      "step=1731, Xent(train)=0.51, Acc(train)=0.81, Xent(valid)=0.67, Acc(valid)=0.79\n",
      "step=1741, Xent(train)=0.49, Acc(train)=0.84, Xent(valid)=0.67, Acc(valid)=0.80\n",
      "step=1751, Xent(train)=0.61, Acc(train)=0.78, Xent(valid)=0.67, Acc(valid)=0.79\n",
      "step=1761, Xent(train)=0.49, Acc(train)=0.85, Xent(valid)=0.66, Acc(valid)=0.79\n",
      "step=1771, Xent(train)=0.48, Acc(train)=0.89, Xent(valid)=0.66, Acc(valid)=0.80\n",
      "step=1781, Xent(train)=0.46, Acc(train)=0.85, Xent(valid)=0.66, Acc(valid)=0.80\n",
      "step=1791, Xent(train)=0.49, Acc(train)=0.84, Xent(valid)=0.66, Acc(valid)=0.80\n",
      "step=1801, Xent(train)=0.62, Acc(train)=0.82, Xent(valid)=0.67, Acc(valid)=0.80\n",
      "step=1811, Xent(train)=0.42, Acc(train)=0.84, Xent(valid)=0.66, Acc(valid)=0.80\n",
      "step=1821, Xent(train)=0.47, Acc(train)=0.84, Xent(valid)=0.66, Acc(valid)=0.80\n",
      "step=1831, Xent(train)=0.56, Acc(train)=0.83, Xent(valid)=0.66, Acc(valid)=0.79\n",
      "step=1841, Xent(train)=0.52, Acc(train)=0.90, Xent(valid)=0.65, Acc(valid)=0.80\n",
      "step=1851, Xent(train)=0.58, Acc(train)=0.86, Xent(valid)=0.65, Acc(valid)=0.80\n",
      "step=1861, Xent(train)=0.37, Acc(train)=0.91, Xent(valid)=0.65, Acc(valid)=0.80\n",
      "step=1871, Xent(train)=0.54, Acc(train)=0.85, Xent(valid)=0.65, Acc(valid)=0.80\n",
      "step=1881, Xent(train)=0.42, Acc(train)=0.91, Xent(valid)=0.65, Acc(valid)=0.80\n",
      "step=1891, Xent(train)=0.45, Acc(train)=0.86, Xent(valid)=0.65, Acc(valid)=0.80\n",
      "step=1901, Xent(train)=0.43, Acc(train)=0.87, Xent(valid)=0.65, Acc(valid)=0.80\n",
      "step=1911, Xent(train)=0.37, Acc(train)=0.91, Xent(valid)=0.65, Acc(valid)=0.80\n",
      "step=1921, Xent(train)=0.68, Acc(train)=0.78, Xent(valid)=0.65, Acc(valid)=0.80\n",
      "step=1931, Xent(train)=0.44, Acc(train)=0.88, Xent(valid)=0.64, Acc(valid)=0.80\n",
      "step=1941, Xent(train)=0.64, Acc(train)=0.83, Xent(valid)=0.64, Acc(valid)=0.81\n",
      "step=1951, Xent(train)=0.42, Acc(train)=0.86, Xent(valid)=0.64, Acc(valid)=0.81\n",
      "step=1961, Xent(train)=0.41, Acc(train)=0.87, Xent(valid)=0.64, Acc(valid)=0.81\n",
      "step=1971, Xent(train)=0.44, Acc(train)=0.88, Xent(valid)=0.65, Acc(valid)=0.81\n",
      "step=1981, Xent(train)=0.43, Acc(train)=0.82, Xent(valid)=0.64, Acc(valid)=0.80\n",
      "step=1991, Xent(train)=0.50, Acc(train)=0.83, Xent(valid)=0.64, Acc(valid)=0.81\n",
      "step=2001, Xent(train)=0.40, Acc(train)=0.88, Xent(valid)=0.64, Acc(valid)=0.81\n",
      "step=2011, Xent(train)=0.27, Acc(train)=0.96, Xent(valid)=0.64, Acc(valid)=0.81\n",
      "step=2021, Xent(train)=0.46, Acc(train)=0.89, Xent(valid)=0.64, Acc(valid)=0.81\n",
      "step=2031, Xent(train)=0.67, Acc(train)=0.81, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2041, Xent(train)=0.42, Acc(train)=0.89, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2051, Xent(train)=0.54, Acc(train)=0.83, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2061, Xent(train)=0.53, Acc(train)=0.85, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2071, Xent(train)=0.34, Acc(train)=0.88, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2081, Xent(train)=0.45, Acc(train)=0.86, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2091, Xent(train)=0.33, Acc(train)=0.90, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2101, Xent(train)=0.33, Acc(train)=0.91, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2111, Xent(train)=0.38, Acc(train)=0.90, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2121, Xent(train)=0.39, Acc(train)=0.90, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2131, Xent(train)=0.39, Acc(train)=0.89, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2141, Xent(train)=0.49, Acc(train)=0.85, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2151, Xent(train)=0.40, Acc(train)=0.87, Xent(valid)=0.63, Acc(valid)=0.81\n",
      "step=2161, Xent(train)=0.60, Acc(train)=0.82, Xent(valid)=0.62, Acc(valid)=0.81\n",
      "step=2171, Xent(train)=0.55, Acc(train)=0.86, Xent(valid)=0.62, Acc(valid)=0.81\n",
      "step=2181, Xent(train)=0.38, Acc(train)=0.89, Xent(valid)=0.62, Acc(valid)=0.82\n",
      "step=2191, Xent(train)=0.43, Acc(train)=0.88, Xent(valid)=0.62, Acc(valid)=0.81\n",
      "step=2201, Xent(train)=0.44, Acc(train)=0.87, Xent(valid)=0.62, Acc(valid)=0.82\n",
      "step=2211, Xent(train)=0.45, Acc(train)=0.88, Xent(valid)=0.62, Acc(valid)=0.82\n",
      "step=2221, Xent(train)=0.56, Acc(train)=0.84, Xent(valid)=0.62, Acc(valid)=0.81\n",
      "step=2231, Xent(train)=0.31, Acc(train)=0.91, Xent(valid)=0.61, Acc(valid)=0.82\n",
      "step=2241, Xent(train)=0.68, Acc(train)=0.77, Xent(valid)=0.61, Acc(valid)=0.82\n",
      "step=2251, Xent(train)=0.31, Acc(train)=0.88, Xent(valid)=0.61, Acc(valid)=0.82\n",
      "step=2261, Xent(train)=0.42, Acc(train)=0.90, Xent(valid)=0.61, Acc(valid)=0.82\n",
      "step=2271, Xent(train)=0.43, Acc(train)=0.86, Xent(valid)=0.61, Acc(valid)=0.82\n",
      "step=2281, Xent(train)=0.46, Acc(train)=0.85, Xent(valid)=0.61, Acc(valid)=0.82\n",
      "step=2291, Xent(train)=0.60, Acc(train)=0.81, Xent(valid)=0.61, Acc(valid)=0.81\n",
      "step=2301, Xent(train)=0.46, Acc(train)=0.84, Xent(valid)=0.61, Acc(valid)=0.82\n",
      "step=2311, Xent(train)=0.40, Acc(train)=0.86, Xent(valid)=0.61, Acc(valid)=0.81\n",
      "step=2321, Xent(train)=0.47, Acc(train)=0.86, Xent(valid)=0.61, Acc(valid)=0.82\n",
      "step=2331, Xent(train)=0.40, Acc(train)=0.90, Xent(valid)=0.61, Acc(valid)=0.81\n",
      "step=2341, Xent(train)=0.32, Acc(train)=0.94, Xent(valid)=0.61, Acc(valid)=0.81\n",
      "step=2351, Xent(train)=0.50, Acc(train)=0.83, Xent(valid)=0.61, Acc(valid)=0.81\n",
      "step=2361, Xent(train)=0.57, Acc(train)=0.81, Xent(valid)=0.60, Acc(valid)=0.82\n",
      "step=2371, Xent(train)=0.71, Acc(train)=0.80, Xent(valid)=0.60, Acc(valid)=0.81\n",
      "step=2381, Xent(train)=0.61, Acc(train)=0.83, Xent(valid)=0.60, Acc(valid)=0.82\n",
      "step=2391, Xent(train)=0.35, Acc(train)=0.88, Xent(valid)=0.61, Acc(valid)=0.81\n",
      "step=2401, Xent(train)=0.62, Acc(train)=0.83, Xent(valid)=0.60, Acc(valid)=0.82\n",
      "step=2411, Xent(train)=0.53, Acc(train)=0.84, Xent(valid)=0.61, Acc(valid)=0.82\n",
      "step=2421, Xent(train)=0.46, Acc(train)=0.88, Xent(valid)=0.60, Acc(valid)=0.82\n",
      "step=2431, Xent(train)=0.40, Acc(train)=0.87, Xent(valid)=0.60, Acc(valid)=0.82\n",
      "step=2441, Xent(train)=0.55, Acc(train)=0.84, Xent(valid)=0.60, Acc(valid)=0.82\n",
      "step=2451, Xent(train)=0.36, Acc(train)=0.84, Xent(valid)=0.60, Acc(valid)=0.82\n",
      "step=2461, Xent(train)=0.40, Acc(train)=0.87, Xent(valid)=0.60, Acc(valid)=0.81\n",
      "step=2471, Xent(train)=0.44, Acc(train)=0.85, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2481, Xent(train)=0.41, Acc(train)=0.89, Xent(valid)=0.60, Acc(valid)=0.82\n",
      "step=2491, Xent(train)=0.45, Acc(train)=0.88, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2501, Xent(train)=0.46, Acc(train)=0.87, Xent(valid)=0.60, Acc(valid)=0.82\n",
      "step=2511, Xent(train)=0.54, Acc(train)=0.85, Xent(valid)=0.60, Acc(valid)=0.81\n",
      "step=2521, Xent(train)=0.51, Acc(train)=0.87, Xent(valid)=0.60, Acc(valid)=0.82\n",
      "step=2531, Xent(train)=0.47, Acc(train)=0.86, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2541, Xent(train)=0.44, Acc(train)=0.87, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2551, Xent(train)=0.34, Acc(train)=0.93, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2561, Xent(train)=0.55, Acc(train)=0.80, Xent(valid)=0.60, Acc(valid)=0.82\n",
      "step=2571, Xent(train)=0.33, Acc(train)=0.90, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2581, Xent(train)=0.35, Acc(train)=0.92, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2591, Xent(train)=0.55, Acc(train)=0.83, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2601, Xent(train)=0.33, Acc(train)=0.90, Xent(valid)=0.58, Acc(valid)=0.82\n",
      "step=2611, Xent(train)=0.50, Acc(train)=0.84, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2621, Xent(train)=0.27, Acc(train)=0.95, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2631, Xent(train)=0.58, Acc(train)=0.85, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2641, Xent(train)=0.57, Acc(train)=0.78, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2651, Xent(train)=0.40, Acc(train)=0.89, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2661, Xent(train)=0.47, Acc(train)=0.86, Xent(valid)=0.59, Acc(valid)=0.81\n",
      "step=2671, Xent(train)=0.32, Acc(train)=0.91, Xent(valid)=0.58, Acc(valid)=0.83\n",
      "step=2681, Xent(train)=0.31, Acc(train)=0.88, Xent(valid)=0.58, Acc(valid)=0.82\n",
      "step=2691, Xent(train)=0.43, Acc(train)=0.87, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2701, Xent(train)=0.38, Acc(train)=0.87, Xent(valid)=0.58, Acc(valid)=0.82\n",
      "step=2711, Xent(train)=0.38, Acc(train)=0.92, Xent(valid)=0.58, Acc(valid)=0.82\n",
      "step=2721, Xent(train)=0.39, Acc(train)=0.87, Xent(valid)=0.58, Acc(valid)=0.82\n",
      "step=2731, Xent(train)=0.44, Acc(train)=0.87, Xent(valid)=0.59, Acc(valid)=0.82\n",
      "step=2741, Xent(train)=0.33, Acc(train)=0.91, Xent(valid)=0.58, Acc(valid)=0.83\n",
      "step=2751, Xent(train)=0.27, Acc(train)=0.90, Xent(valid)=0.58, Acc(valid)=0.82\n",
      "step=2761, Xent(train)=0.36, Acc(train)=0.87, Xent(valid)=0.57, Acc(valid)=0.82\n",
      "step=2771, Xent(train)=0.30, Acc(train)=0.94, Xent(valid)=0.58, Acc(valid)=0.83\n",
      "step=2781, Xent(train)=0.47, Acc(train)=0.83, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2791, Xent(train)=0.28, Acc(train)=0.91, Xent(valid)=0.58, Acc(valid)=0.82\n",
      "step=2801, Xent(train)=0.48, Acc(train)=0.86, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2811, Xent(train)=0.39, Acc(train)=0.87, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2821, Xent(train)=0.42, Acc(train)=0.87, Xent(valid)=0.58, Acc(valid)=0.83\n",
      "step=2831, Xent(train)=0.38, Acc(train)=0.86, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2841, Xent(train)=0.36, Acc(train)=0.91, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2851, Xent(train)=0.39, Acc(train)=0.86, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2861, Xent(train)=0.47, Acc(train)=0.87, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2871, Xent(train)=0.45, Acc(train)=0.85, Xent(valid)=0.57, Acc(valid)=0.82\n",
      "step=2881, Xent(train)=0.46, Acc(train)=0.87, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2891, Xent(train)=0.53, Acc(train)=0.84, Xent(valid)=0.57, Acc(valid)=0.82\n",
      "step=2901, Xent(train)=0.35, Acc(train)=0.84, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2911, Xent(train)=0.42, Acc(train)=0.86, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=2921, Xent(train)=0.25, Acc(train)=0.94, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2931, Xent(train)=0.57, Acc(train)=0.88, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2941, Xent(train)=0.58, Acc(train)=0.80, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2951, Xent(train)=0.40, Acc(train)=0.87, Xent(valid)=0.57, Acc(valid)=0.83\n",
      "step=2961, Xent(train)=0.41, Acc(train)=0.88, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=2971, Xent(train)=0.29, Acc(train)=0.93, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=2981, Xent(train)=0.28, Acc(train)=0.93, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=2991, Xent(train)=0.23, Acc(train)=0.92, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=3001, Xent(train)=0.35, Acc(train)=0.88, Xent(valid)=0.55, Acc(valid)=0.84\n",
      "step=3011, Xent(train)=0.42, Acc(train)=0.87, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=3021, Xent(train)=0.29, Acc(train)=0.91, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=3031, Xent(train)=0.24, Acc(train)=0.94, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=3041, Xent(train)=0.27, Acc(train)=0.93, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=3051, Xent(train)=0.62, Acc(train)=0.83, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=3061, Xent(train)=0.39, Acc(train)=0.84, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=3071, Xent(train)=0.47, Acc(train)=0.88, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=3081, Xent(train)=0.33, Acc(train)=0.91, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3091, Xent(train)=0.37, Acc(train)=0.89, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3101, Xent(train)=0.39, Acc(train)=0.92, Xent(valid)=0.55, Acc(valid)=0.84\n",
      "step=3111, Xent(train)=0.34, Acc(train)=0.87, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3121, Xent(train)=0.38, Acc(train)=0.90, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3131, Xent(train)=0.39, Acc(train)=0.90, Xent(valid)=0.56, Acc(valid)=0.83\n",
      "step=3141, Xent(train)=0.40, Acc(train)=0.88, Xent(valid)=0.55, Acc(valid)=0.84\n",
      "step=3151, Xent(train)=0.38, Acc(train)=0.87, Xent(valid)=0.55, Acc(valid)=0.84\n",
      "step=3161, Xent(train)=0.35, Acc(train)=0.91, Xent(valid)=0.55, Acc(valid)=0.84\n",
      "step=3171, Xent(train)=0.30, Acc(train)=0.93, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3181, Xent(train)=0.21, Acc(train)=0.94, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3191, Xent(train)=0.44, Acc(train)=0.89, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3201, Xent(train)=0.46, Acc(train)=0.87, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3211, Xent(train)=0.31, Acc(train)=0.92, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3221, Xent(train)=0.41, Acc(train)=0.89, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3231, Xent(train)=0.29, Acc(train)=0.93, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3241, Xent(train)=0.31, Acc(train)=0.93, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3251, Xent(train)=0.30, Acc(train)=0.90, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3261, Xent(train)=0.31, Acc(train)=0.93, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3271, Xent(train)=0.48, Acc(train)=0.86, Xent(valid)=0.55, Acc(valid)=0.84\n",
      "step=3281, Xent(train)=0.45, Acc(train)=0.84, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3291, Xent(train)=0.31, Acc(train)=0.90, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3301, Xent(train)=0.33, Acc(train)=0.93, Xent(valid)=0.54, Acc(valid)=0.83\n",
      "step=3311, Xent(train)=0.22, Acc(train)=0.94, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3321, Xent(train)=0.28, Acc(train)=0.96, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3331, Xent(train)=0.30, Acc(train)=0.92, Xent(valid)=0.54, Acc(valid)=0.83\n",
      "step=3341, Xent(train)=0.32, Acc(train)=0.89, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3351, Xent(train)=0.24, Acc(train)=0.94, Xent(valid)=0.54, Acc(valid)=0.83\n",
      "step=3361, Xent(train)=0.32, Acc(train)=0.86, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3371, Xent(train)=0.43, Acc(train)=0.88, Xent(valid)=0.54, Acc(valid)=0.83\n",
      "step=3381, Xent(train)=0.30, Acc(train)=0.91, Xent(valid)=0.54, Acc(valid)=0.83\n",
      "step=3391, Xent(train)=0.34, Acc(train)=0.88, Xent(valid)=0.54, Acc(valid)=0.83\n",
      "step=3401, Xent(train)=0.40, Acc(train)=0.88, Xent(valid)=0.55, Acc(valid)=0.83\n",
      "step=3411, Xent(train)=0.29, Acc(train)=0.92, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3421, Xent(train)=0.33, Acc(train)=0.92, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3431, Xent(train)=0.34, Acc(train)=0.88, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3441, Xent(train)=0.34, Acc(train)=0.91, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3451, Xent(train)=0.34, Acc(train)=0.93, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3461, Xent(train)=0.26, Acc(train)=0.92, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3471, Xent(train)=0.35, Acc(train)=0.90, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3481, Xent(train)=0.50, Acc(train)=0.86, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3491, Xent(train)=0.35, Acc(train)=0.91, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3501, Xent(train)=0.33, Acc(train)=0.86, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3511, Xent(train)=0.28, Acc(train)=0.89, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3521, Xent(train)=0.37, Acc(train)=0.88, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3531, Xent(train)=0.48, Acc(train)=0.85, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3541, Xent(train)=0.38, Acc(train)=0.86, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3551, Xent(train)=0.42, Acc(train)=0.88, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3561, Xent(train)=0.28, Acc(train)=0.92, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3571, Xent(train)=0.39, Acc(train)=0.89, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3581, Xent(train)=0.20, Acc(train)=0.96, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3591, Xent(train)=0.31, Acc(train)=0.88, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3601, Xent(train)=0.34, Acc(train)=0.89, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3611, Xent(train)=0.40, Acc(train)=0.88, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3621, Xent(train)=0.43, Acc(train)=0.89, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3631, Xent(train)=0.45, Acc(train)=0.89, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3641, Xent(train)=0.52, Acc(train)=0.86, Xent(valid)=0.54, Acc(valid)=0.84\n",
      "step=3651, Xent(train)=0.26, Acc(train)=0.93, Xent(valid)=0.54, Acc(valid)=0.83\n",
      "step=3661, Xent(train)=0.37, Acc(train)=0.93, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3671, Xent(train)=0.24, Acc(train)=0.94, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3681, Xent(train)=0.29, Acc(train)=0.90, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3691, Xent(train)=0.33, Acc(train)=0.90, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3701, Xent(train)=0.29, Acc(train)=0.94, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3711, Xent(train)=0.28, Acc(train)=0.94, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3721, Xent(train)=0.38, Acc(train)=0.92, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3731, Xent(train)=0.35, Acc(train)=0.91, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3741, Xent(train)=0.33, Acc(train)=0.90, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3751, Xent(train)=0.37, Acc(train)=0.85, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3761, Xent(train)=0.33, Acc(train)=0.92, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3771, Xent(train)=0.30, Acc(train)=0.93, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3781, Xent(train)=0.46, Acc(train)=0.88, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3791, Xent(train)=0.28, Acc(train)=0.94, Xent(valid)=0.52, Acc(valid)=0.84\n",
      "step=3801, Xent(train)=0.35, Acc(train)=0.89, Xent(valid)=0.52, Acc(valid)=0.84\n",
      "step=3811, Xent(train)=0.32, Acc(train)=0.89, Xent(valid)=0.52, Acc(valid)=0.84\n",
      "step=3821, Xent(train)=0.40, Acc(train)=0.86, Xent(valid)=0.52, Acc(valid)=0.84\n",
      "step=3831, Xent(train)=0.36, Acc(train)=0.90, Xent(valid)=0.52, Acc(valid)=0.84\n",
      "step=3841, Xent(train)=0.44, Acc(train)=0.90, Xent(valid)=0.53, Acc(valid)=0.84\n",
      "step=3851, Xent(train)=0.20, Acc(train)=0.96, Xent(valid)=0.52, Acc(valid)=0.84\n",
      "step=3861, Xent(train)=0.29, Acc(train)=0.92, Xent(valid)=0.52, Acc(valid)=0.84\n",
      "step=3871, Xent(train)=0.31, Acc(train)=0.93, Xent(valid)=0.52, Acc(valid)=0.85\n",
      "step=3881, Xent(train)=0.29, Acc(train)=0.91, Xent(valid)=0.52, Acc(valid)=0.85\n",
      "step=3891, Xent(train)=0.27, Acc(train)=0.93, Xent(valid)=0.52, Acc(valid)=0.85\n",
      "step=3901, Xent(train)=0.31, Acc(train)=0.90, Xent(valid)=0.51, Acc(valid)=0.84\n",
      "step=3911, Xent(train)=0.23, Acc(train)=0.94, Xent(valid)=0.52, Acc(valid)=0.85\n",
      "step=3921, Xent(train)=0.30, Acc(train)=0.91, Xent(valid)=0.52, Acc(valid)=0.85\n",
      "step=3931, Xent(train)=0.29, Acc(train)=0.90, Xent(valid)=0.52, Acc(valid)=0.85\n",
      "step=3941, Xent(train)=0.37, Acc(train)=0.89, Xent(valid)=0.52, Acc(valid)=0.84\n",
      "step=3951, Xent(train)=0.26, Acc(train)=0.92, Xent(valid)=0.52, Acc(valid)=0.84\n",
      "step=3961, Xent(train)=0.26, Acc(train)=0.92, Xent(valid)=0.52, Acc(valid)=0.85\n",
      "step=3971, Xent(train)=0.35, Acc(train)=0.90, Xent(valid)=0.52, Acc(valid)=0.85\n",
      "step=3981, Xent(train)=0.32, Acc(train)=0.89, Xent(valid)=0.52, Acc(valid)=0.85\n",
      "step=3991, Xent(train)=0.34, Acc(train)=0.92, Xent(valid)=0.52, Acc(valid)=0.85\n",
      "step=4001, Xent(train)=0.21, Acc(train)=0.93, Xent(valid)=0.52, Acc(valid)=0.85\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN_SAMPLES = 1000  # ★ 変えてみよう\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_images_subset = mnist.train.images[:NUM_TRAIN_SAMPLES]\n",
    "train_labels_subset = mnist.train.labels[:NUM_TRAIN_SAMPLES]\n",
    "\n",
    "for i in range(2001):  # ★ 増やしてみよう\n",
    "    # バッチ型確率的勾配降下法でパラメータ更新\n",
    "    batch_xs, batch_ys = resample(train_images_subset, train_labels_subset, n_samples = BATCH_SIZE)\n",
    "    _, train_xent, train_acc, train_merged_summ, step = sess.run(\n",
    "        [train_step, loss, acc, merged_summ, global_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    train_writer.add_summary(train_merged_summ, step)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        # 10回の更新ごとに予測性能を出力\n",
    "        valid_xent, valid_acc, valid_merged_summ, step = sess.run([loss, acc, merged_summ, global_step], \n",
    "                                         feed_dict={x: mnist.validation.images[0:1000], y_: mnist.validation.labels[0:1000]})\n",
    "        valid_writer.add_summary(valid_merged_summ, step)\n",
    "        print (\"step=%3d, Xent(train)=%.2f, Acc(train)=%.2f, Xent(valid)=%.2f, Acc(valid)=%.2f\" % \n",
    "               (step, train_xent, train_acc, valid_xent, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# バッファ内のサマリーデータを出力する\n",
    "train_writer.flush()\n",
    "valid_writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 後片付け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# セッションを閉じる\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
